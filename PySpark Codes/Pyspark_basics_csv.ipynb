{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EL6YMnoavzqx",
        "5B7_e5nTxY4k"
      ],
      "authorship_tag": "ABX9TyPbttiyLYGbgy4kHDNxiTso",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Ny/PySpark/blob/main/Pyspark_basics_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "id": "5ekwl_kMclyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To load and analyse the fakefriends.csv data | Data Frame reader and writer."
      ],
      "metadata": {
        "id": "EL6YMnoavzqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "import pyspark.sql.functions as func"
      ],
      "metadata": {
        "id": "PW90BFQ3f4I9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the SparkSession\n",
        "spark_fakefriends = SparkSession.builder.appName(\"FirstApp\").getOrCreate()"
      ],
      "metadata": {
        "id": "yXw3xXfzhHRj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining schema for your Dataframe\n",
        "myschema = StructType([\\\n",
        "                       StructField(\"userID\", IntegerType(),True), #True means is nullable\n",
        "                       StructField(\"name\", StringType(),True),\n",
        "                       StructField(\"age\", IntegerType(),True),\n",
        "                       StructField(\"friends\", IntegerType(),True)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "pqfEBiA9kB81"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Dataframe on a CSV file\n",
        "people = spark_fakefriends.read.format(\"CSV\")\\\n",
        "      .schema(myschema)\\\n",
        "      .option(\"path\",\"/content/fakefriends.csv\")\\\n",
        "      .load()\n",
        "\n",
        "people.printSchema()"
      ],
      "metadata": {
        "id": "TFaFwxlUkuOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4c3765-6a6b-4f9e-9ee8-23bb963b9549"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- friends: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing all the transformations\n",
        "output=people.select(people.userID,people.name,people.age,people.friends).where(people.age<30).withColumn('insert_timestamp',func.current_timestamp()).orderBy(people.userID).cache()"
      ],
      "metadata": {
        "id": "rAZwExWGdTVK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking the count of o/p dataframe\n",
        "output.show()"
      ],
      "metadata": {
        "id": "cGzXhoIcm4GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a Temp View\n",
        "output.createOrReplaceTempView(\"peoples\")"
      ],
      "metadata": {
        "id": "J4Hg7DqReTX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running a simple Spark SQL query\n",
        "spark_fakefriends.sql(\"select userId,name,age,friends,insert_timestamp from peoples\").show()"
      ],
      "metadata": {
        "id": "jMG6Aha6eg96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.write\\\n",
        ".format(\"CSV\")\\\n",
        ".mode(\"overwrite\")\\\n",
        ".option('path','/content/spark-warehouse/')\\\n",
        ".bucketBy(4,'age')\\\n",
        ".saveAsTable('bucketed_fakefreinds')"
      ],
      "metadata": {
        "id": "Dmmtf7yiLPMM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucketed_fakefreinds_df = spark_fakefriends.sql('select * from bucketed_fakefreinds')\n",
        "bucketed_fakefreinds_df.show(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa7Q9bavNvNb",
        "outputId": "b506a22c-61cb-4d91-94f8-b0d3e732542c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---+-------+--------------------+\n",
            "|userID|    name|age|friends|    insert_timestamp|\n",
            "+------+--------+---+-------+--------------------+\n",
            "|     1|Jean-Luc| 26|      2|2024-02-17 08:26:...|\n",
            "|     9|    Hugh| 27|    181|2024-02-17 08:26:...|\n",
            "|    25|     Ben| 21|    445|2024-02-17 08:26:...|\n",
            "|    32|     Nog| 26|    281|2024-02-17 08:26:...|\n",
            "|    35| Beverly| 27|    305|2024-02-17 08:26:...|\n",
            "|    47|   Brunt| 24|     49|2024-02-17 08:26:...|\n",
            "|    66|  Geordi| 21|    477|2024-02-17 08:26:...|\n",
            "|    89|    Worf| 24|    492|2024-02-17 08:26:...|\n",
            "|   126|   Brunt| 26|     84|2024-02-17 08:26:...|\n",
            "|   165|   Leeta| 26|    282|2024-02-17 08:26:...|\n",
            "|   178|  Kasidy| 26|    381|2024-02-17 08:26:...|\n",
            "|   182|  Weyoun| 26|    145|2024-02-17 08:26:...|\n",
            "|   200|  Kasidy| 21|    472|2024-02-17 08:26:...|\n",
            "|   206|    Will| 21|    491|2024-02-17 08:26:...|\n",
            "|   209|   Brunt| 27|    174|2024-02-17 08:26:...|\n",
            "|   219| Lwaxana| 26|    345|2024-02-17 08:26:...|\n",
            "|   221|   Dukat| 27|    150|2024-02-17 08:26:...|\n",
            "|   228|  Martok| 26|    293|2024-02-17 08:26:...|\n",
            "|   229|  Gowron| 24|    150|2024-02-17 08:26:...|\n",
            "|   244|   Dukat| 21|    471|2024-02-17 08:26:...|\n",
            "|   248|   Dukat| 21|    138|2024-02-17 08:26:...|\n",
            "|   265|  Gowron| 27|    471|2024-02-17 08:26:...|\n",
            "|   268|    Ezri| 26|    298|2024-02-17 08:26:...|\n",
            "|   280|   Nerys| 26|    492|2024-02-17 08:26:...|\n",
            "|   281|    Worf| 21|     89|2024-02-17 08:26:...|\n",
            "|   284|     Nog| 26|    269|2024-02-17 08:26:...|\n",
            "|   335|     Odo| 27|    337|2024-02-17 08:26:...|\n",
            "|   343|     Odo| 26|    254|2024-02-17 08:26:...|\n",
            "|   352|  Deanna| 27|     53|2024-02-17 08:26:...|\n",
            "|   357|   Brunt| 26|      7|2024-02-17 08:26:...|\n",
            "|   368|    Elim| 26|    383|2024-02-17 08:26:...|\n",
            "|   398| Lwaxana| 26|    124|2024-02-17 08:26:...|\n",
            "|   399| Beverly| 24|    401|2024-02-17 08:26:...|\n",
            "|   403|  Weyoun| 21|    224|2024-02-17 08:26:...|\n",
            "|   420|  Jadzia| 26|    391|2024-02-17 08:26:...|\n",
            "|   426|    Worf| 24|     77|2024-02-17 08:26:...|\n",
            "|   459|  Geordi| 26|     84|2024-02-17 08:26:...|\n",
            "|   472|     Nog| 27|    154|2024-02-17 08:26:...|\n",
            "|    21|   Miles| 19|    268|2024-02-17 08:26:...|\n",
            "|    48|     Nog| 20|      1|2024-02-17 08:26:...|\n",
            "|    52| Beverly| 19|    269|2024-02-17 08:26:...|\n",
            "|    54|   Brunt| 19|      5|2024-02-17 08:26:...|\n",
            "|    60|  Geordi| 20|    100|2024-02-17 08:26:...|\n",
            "|    73|   Brunt| 20|    384|2024-02-17 08:26:...|\n",
            "|    95|     Odo| 29|    173|2024-02-17 08:26:...|\n",
            "|   119|    Worf| 29|    344|2024-02-17 08:26:...|\n",
            "|   133|   Quark| 19|    265|2024-02-17 08:26:...|\n",
            "|   136|    Will| 19|    335|2024-02-17 08:26:...|\n",
            "|   171|  Weyoun| 29|    126|2024-02-17 08:26:...|\n",
            "|   173|   Leeta| 23|    129|2024-02-17 08:26:...|\n",
            "|   201|    Ezri| 23|    174|2024-02-17 08:26:...|\n",
            "|   217|   Keiko| 29|    260|2024-02-17 08:26:...|\n",
            "|   225|    Elim| 19|    106|2024-02-17 08:26:...|\n",
            "|   259|  Kasidy| 29|     11|2024-02-17 08:26:...|\n",
            "|   264|  Julian| 29|    228|2024-02-17 08:26:...|\n",
            "|   272|   Quark| 29|    367|2024-02-17 08:26:...|\n",
            "|   279| Beverly| 23|    133|2024-02-17 08:26:...|\n",
            "|   291|   Dukat| 23|    373|2024-02-17 08:26:...|\n",
            "|   293|  Deanna| 23|     65|2024-02-17 08:26:...|\n",
            "|   304|    Will| 19|    404|2024-02-17 08:26:...|\n",
            "|   305|   Quark| 29|    182|2024-02-17 08:26:...|\n",
            "|   306| Beverly| 23|    323|2024-02-17 08:26:...|\n",
            "|   323|     Nog| 29|    236|2024-02-17 08:26:...|\n",
            "|   327|  Julian| 20|     63|2024-02-17 08:26:...|\n",
            "|   333|     Ben| 29|    207|2024-02-17 08:26:...|\n",
            "|   346|    Hugh| 29|    329|2024-02-17 08:26:...|\n",
            "|   349|  Kasidy| 20|    277|2024-02-17 08:26:...|\n",
            "|   366|   Keiko| 19|    119|2024-02-17 08:26:...|\n",
            "|   373|   Quark| 19|    272|2024-02-17 08:26:...|\n",
            "|   376|  Gowron| 23|    392|2024-02-17 08:26:...|\n",
            "|   394|   Keiko| 23|    230|2024-02-17 08:26:...|\n",
            "|   400|    Data| 29|    128|2024-02-17 08:26:...|\n",
            "|   409|     Nog| 19|    267|2024-02-17 08:26:...|\n",
            "|   462|   Nerys| 23|    287|2024-02-17 08:26:...|\n",
            "|   492|   Dukat| 19|     36|2024-02-17 08:26:...|\n",
            "|   493|    Hugh| 23|    357|2024-02-17 08:26:...|\n",
            "|    24|  Julian| 25|      1|2024-02-17 08:26:...|\n",
            "|    46|    Morn| 25|     96|2024-02-17 08:26:...|\n",
            "|    96|    Ezri| 25|    233|2024-02-17 08:26:...|\n",
            "|   106| Beverly| 18|    499|2024-02-17 08:26:...|\n",
            "|   108|   Leeta| 25|    274|2024-02-17 08:26:...|\n",
            "|   112|    Morn| 25|     13|2024-02-17 08:26:...|\n",
            "|   115|   Dukat| 18|    397|2024-02-17 08:26:...|\n",
            "|   166| Lwaxana| 25|     10|2024-02-17 08:26:...|\n",
            "|   238|  Deanna| 25|    305|2024-02-17 08:26:...|\n",
            "|   242|    Data| 25|    101|2024-02-17 08:26:...|\n",
            "|   271|    Morn| 25|    446|2024-02-17 08:26:...|\n",
            "|   315|  Weyoun| 25|    208|2024-02-17 08:26:...|\n",
            "|   341|    Data| 18|    326|2024-02-17 08:26:...|\n",
            "|   377| Beverly| 18|    418|2024-02-17 08:26:...|\n",
            "|   404|  Kasidy| 18|     24|2024-02-17 08:26:...|\n",
            "|   439|    Data| 18|    417|2024-02-17 08:26:...|\n",
            "|   444|   Keiko| 18|    472|2024-02-17 08:26:...|\n",
            "|   464| Beverly| 25|    485|2024-02-17 08:26:...|\n",
            "|   494|  Kasidy| 18|    194|2024-02-17 08:26:...|\n",
            "|    16|  Weyoun| 22|    323|2024-02-17 08:26:...|\n",
            "|    26|  Julian| 22|    100|2024-02-17 08:26:...|\n",
            "|    72|  Kasidy| 22|    179|2024-02-17 08:26:...|\n",
            "|    84|     Ben| 28|    311|2024-02-17 08:26:...|\n",
            "|   118|     Ben| 28|    304|2024-02-17 08:26:...|\n",
            "|   137|  Martok| 28|     32|2024-02-17 08:26:...|\n",
            "|   144|   Miles| 22|     93|2024-02-17 08:26:...|\n",
            "|   213|    Worf| 28|    312|2024-02-17 08:26:...|\n",
            "|   215|    Will| 22|      6|2024-02-17 08:26:...|\n",
            "|   245|Jean-Luc| 28|    174|2024-02-17 08:26:...|\n",
            "|   301|  Weyoun| 28|    108|2024-02-17 08:26:...|\n",
            "|   338|    Will| 28|    180|2024-02-17 08:26:...|\n",
            "|   390|  Martok| 22|    266|2024-02-17 08:26:...|\n",
            "|   427|   Brunt| 28|    258|2024-02-17 08:26:...|\n",
            "|   451|  Martok| 28|     34|2024-02-17 08:26:...|\n",
            "|   476|Jean-Luc| 28|    378|2024-02-17 08:26:...|\n",
            "|   484|   Leeta| 22|    478|2024-02-17 08:26:...|\n",
            "+------+--------+---+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To load and analyse the operations_management.csv data."
      ],
      "metadata": {
        "id": "5B7_e5nTxY4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, desc"
      ],
      "metadata": {
        "id": "6hz-iKi-xk-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_operations = SparkSession.builder.appName('operations_management data analisation').getOrCreate()"
      ],
      "metadata": {
        "id": "SiYlwzFWjBsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.version)"
      ],
      "metadata": {
        "id": "fNvHX_g5jT3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fd4bbe-3abd-4a11-aeac-08357a8cf76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = spark_operations.read.format('CSV').\\\n",
        "option('inferSchema','true').\\\n",
        "option('header','true').\\\n",
        "option('path','/content/operations_management.csv').\\\n",
        "load()"
      ],
      "metadata": {
        "id": "cDDV6YDVjllP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.printSchema()"
      ],
      "metadata": {
        "id": "nVllKFQgm2N3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b942135-12aa-40ec-af03-7fc0257502b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- description: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- level: integer (nullable = true)\n",
            " |-- size: string (nullable = true)\n",
            " |-- line_code: string (nullable = true)\n",
            " |-- value: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2 = data_frame.select('industry','value').\\\n",
        "where(data_frame.value > 10000).\\\n",
        "orderBy(desc('value'))"
      ],
      "metadata": {
        "id": "lRO05ziFn20V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2.printSchema()"
      ],
      "metadata": {
        "id": "VCea1fIOpnKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfab36d8-3ad4-4ebb-d7aa-1d006cb5b2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- industry: string (nullable = true)\n",
            " |-- value: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2.show(5)"
      ],
      "metadata": {
        "id": "v4Vq2npyqg4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dfadff-4e27-4c32-8248-a8102151abbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|industry|value|\n",
            "+--------+-----+\n",
            "|   total|41091|\n",
            "|   total|40431|\n",
            "|   total|33984|\n",
            "|   total|33750|\n",
            "|   total|32652|\n",
            "+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or we can use filter instead of where clause to filter using value columns\n",
        "data_frame_3 = data_frame.select('industry','value').\\\n",
        "filter((col('value') > 200) & (col('industry') != 'total')).\\\n",
        "orderBy(desc('value'))"
      ],
      "metadata": {
        "id": "2mQT1ox6pvp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_3.printSchema()"
      ],
      "metadata": {
        "id": "p1sSSqL6qb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa211b7-b000-4606-f3f3-5e617391dc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- industry: string (nullable = true)\n",
            " |-- value: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_3.show(5)"
      ],
      "metadata": {
        "id": "nabI5mSLqnnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94569850-9582-461d-9b7d-4f038de5632c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            industry|value|\n",
            "+--------------------+-----+\n",
            "|        Construction| 6030|\n",
            "|        Construction| 5904|\n",
            "|        Construction| 5229|\n",
            "|Accommodation & f...| 5058|\n",
            "|        Construction| 4965|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Temp View\n",
        "data_frame_3.createOrReplaceTempView('data') #Here data is any name given to view"
      ],
      "metadata": {
        "id": "kFfD3tuUwMa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the temp view data\n",
        "spark_operations.sql('''select industry, value\n",
        "from data\n",
        "where value >200 and\n",
        "industry !=\"total\" order by value desc\n",
        "''').show(5)"
      ],
      "metadata": {
        "id": "vJu31L62xUB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69dabe6a-3e90-4239-e138-4730b67b5831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            industry|value|\n",
            "+--------------------+-----+\n",
            "|        Construction| 6030|\n",
            "|        Construction| 5904|\n",
            "|        Construction| 5229|\n",
            "|Accommodation & f...| 5058|\n",
            "|        Construction| 4965|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Create Global and Section Scope view using operations_management.csv data"
      ],
      "metadata": {
        "id": "yraf-sckGRRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, desc"
      ],
      "metadata": {
        "id": "_YGAbi1TGozc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_operations = SparkSession.builder.appName('operations_management data analisation').getOrCreate()"
      ],
      "metadata": {
        "id": "x8TDR87yGozj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark_operations.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e6adc3-03dd-4397-c603-6b04d8ab2dac",
        "id": "Wrh164A-Gozj"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = spark_operations.read.format('CSV').\\\n",
        "option('inferSchema','true').\\\n",
        "option('header','true').\\\n",
        "option('path','/content/operations_management.csv').\\\n",
        "load()"
      ],
      "metadata": {
        "id": "_3CWZlBaGozj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bb9b8f-944c-4a87-fe81-b511ac459ea6",
        "id": "bsnRKk7NGozk"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- description: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- level: integer (nullable = true)\n",
            " |-- size: string (nullable = true)\n",
            " |-- line_code: string (nullable = true)\n",
            " |-- value: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.createOrReplaceGlobalTempView(\"test\")"
      ],
      "metadata": {
        "id": "f680AN9bHajS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_4 = spark_operations.sql('select * from test')\n",
        "data_frame_4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "XJ97EKwAHQrW",
        "outputId": "03b3b9c7-23d8-4dc9-c84c-3b6858453a40"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `test` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [test], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1d7f87c92042>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_frame_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_operations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select * from test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_frame_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `test` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [test], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spark_operations.catalog.dropGlobalTempView('test')\n",
        "spark_operations.catalog.listDatabases()"
      ],
      "metadata": {
        "id": "rqarAwJIJpFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa68a0d-2940-42d9-dc43-22273484baf2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Database(name='default', catalog='spark_catalog', description='default database', locationUri='file:/content/spark-warehouse')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming spark is your SparkSession object\n",
        "global_temp_views = spark_operations.catalog.listTables(\"global_temp\")\n",
        "\n",
        "# Print the list of global temporary views\n",
        "for view in global_temp_views:\n",
        "    print(view)\n"
      ],
      "metadata": {
        "id": "s3ndHYufJtZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ebea8d-b485-469d-9a40-a63d6cbf084d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table(name='test', catalog=None, namespace=['global_temp'], description=None, tableType='TEMPORARY', isTemporary=True)\n"
          ]
        }
      ]
    }
  ]
}