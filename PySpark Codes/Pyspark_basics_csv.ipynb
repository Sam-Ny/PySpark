{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EL6YMnoavzqx",
        "5B7_e5nTxY4k"
      ],
      "authorship_tag": "ABX9TyO3BPXDz3//gZj4oPS1Ax+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sam-Ny/PySpark/blob/main/Pyspark_basics_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "id": "5ekwl_kMclyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To load and analyse the fakefriends.csv data."
      ],
      "metadata": {
        "id": "EL6YMnoavzqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "import pyspark.sql.functions as func"
      ],
      "metadata": {
        "id": "PW90BFQ3f4I9"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the SparkSession\n",
        "spark_fakefriends = SparkSession.builder.appName(\"FirstApp\").getOrCreate()"
      ],
      "metadata": {
        "id": "yXw3xXfzhHRj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining schema for your Dataframe\n",
        "myschema = StructType([\\\n",
        "                       StructField(\"userID\", IntegerType(),True), #True means is nullable\n",
        "                       StructField(\"name\", StringType(),True),\n",
        "                       StructField(\"age\", IntegerType(),True),\n",
        "                       StructField(\"friends\", IntegerType(),True)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "pqfEBiA9kB81"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Dataframe on a CSV file\n",
        "people = spark.read.format(\"CSV\")\\\n",
        "      .schema(myschema)\\\n",
        "      .option(\"path\",\"/content/fakefriends.csv\")\\\n",
        "      .load()"
      ],
      "metadata": {
        "id": "TFaFwxlUkuOt"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing all the transformations\n",
        "output=people.select(people.userID,people.name,people.age,people.friends).where(people.age<30).withColumn('insert_timestamp',func.current_timestamp()).orderBy(people.userID)"
      ],
      "metadata": {
        "id": "rAZwExWGdTVK"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking the count of o/p dataframe\n",
        "output.show()"
      ],
      "metadata": {
        "id": "cGzXhoIcm4GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ed46c0-19cc-4147-8448-892cb49a9228"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---+-------+--------------------+\n",
            "|userID|    name|age|friends|    insert_timestamp|\n",
            "+------+--------+---+-------+--------------------+\n",
            "|     1|Jean-Luc| 26|      2|2024-02-15 08:04:...|\n",
            "|     9|    Hugh| 27|    181|2024-02-15 08:04:...|\n",
            "|    16|  Weyoun| 22|    323|2024-02-15 08:04:...|\n",
            "|    21|   Miles| 19|    268|2024-02-15 08:04:...|\n",
            "|    24|  Julian| 25|      1|2024-02-15 08:04:...|\n",
            "|    25|     Ben| 21|    445|2024-02-15 08:04:...|\n",
            "|    26|  Julian| 22|    100|2024-02-15 08:04:...|\n",
            "|    32|     Nog| 26|    281|2024-02-15 08:04:...|\n",
            "|    35| Beverly| 27|    305|2024-02-15 08:04:...|\n",
            "|    46|    Morn| 25|     96|2024-02-15 08:04:...|\n",
            "|    47|   Brunt| 24|     49|2024-02-15 08:04:...|\n",
            "|    48|     Nog| 20|      1|2024-02-15 08:04:...|\n",
            "|    52| Beverly| 19|    269|2024-02-15 08:04:...|\n",
            "|    54|   Brunt| 19|      5|2024-02-15 08:04:...|\n",
            "|    60|  Geordi| 20|    100|2024-02-15 08:04:...|\n",
            "|    66|  Geordi| 21|    477|2024-02-15 08:04:...|\n",
            "|    72|  Kasidy| 22|    179|2024-02-15 08:04:...|\n",
            "|    73|   Brunt| 20|    384|2024-02-15 08:04:...|\n",
            "|    84|     Ben| 28|    311|2024-02-15 08:04:...|\n",
            "|    89|    Worf| 24|    492|2024-02-15 08:04:...|\n",
            "+------+--------+---+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a Temp View\n",
        "output.createOrReplaceTempView(\"peoples\")"
      ],
      "metadata": {
        "id": "J4Hg7DqReTX7"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running a simple Spark SQL query\n",
        "spark.sql(\"select userId,name,age,friends,insert_timestamp from peoples\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMG6Aha6eg96",
        "outputId": "e0fed632-8b03-4ebc-cd0d-c62d29d83a93"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---+-------+--------------------+\n",
            "|userId|    name|age|friends|    insert_timestamp|\n",
            "+------+--------+---+-------+--------------------+\n",
            "|     1|Jean-Luc| 26|      2|2024-02-15 08:04:...|\n",
            "|     9|    Hugh| 27|    181|2024-02-15 08:04:...|\n",
            "|    16|  Weyoun| 22|    323|2024-02-15 08:04:...|\n",
            "|    21|   Miles| 19|    268|2024-02-15 08:04:...|\n",
            "|    24|  Julian| 25|      1|2024-02-15 08:04:...|\n",
            "|    25|     Ben| 21|    445|2024-02-15 08:04:...|\n",
            "|    26|  Julian| 22|    100|2024-02-15 08:04:...|\n",
            "|    32|     Nog| 26|    281|2024-02-15 08:04:...|\n",
            "|    35| Beverly| 27|    305|2024-02-15 08:04:...|\n",
            "|    46|    Morn| 25|     96|2024-02-15 08:04:...|\n",
            "|    47|   Brunt| 24|     49|2024-02-15 08:04:...|\n",
            "|    48|     Nog| 20|      1|2024-02-15 08:04:...|\n",
            "|    52| Beverly| 19|    269|2024-02-15 08:04:...|\n",
            "|    54|   Brunt| 19|      5|2024-02-15 08:04:...|\n",
            "|    60|  Geordi| 20|    100|2024-02-15 08:04:...|\n",
            "|    66|  Geordi| 21|    477|2024-02-15 08:04:...|\n",
            "|    72|  Kasidy| 22|    179|2024-02-15 08:04:...|\n",
            "|    73|   Brunt| 20|    384|2024-02-15 08:04:...|\n",
            "|    84|     Ben| 28|    311|2024-02-15 08:04:...|\n",
            "|    89|    Worf| 24|    492|2024-02-15 08:04:...|\n",
            "+------+--------+---+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To load and analyse the operations_management.csv data."
      ],
      "metadata": {
        "id": "5B7_e5nTxY4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, desc"
      ],
      "metadata": {
        "id": "6hz-iKi-xk-U"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_operations = SparkSession.builder.appName('operations_management data analisation').getOrCreate()"
      ],
      "metadata": {
        "id": "SiYlwzFWjBsR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.version)"
      ],
      "metadata": {
        "id": "fNvHX_g5jT3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame = spark_operations.read.format('CSV').\\\n",
        "option('inferSchema','true').\\\n",
        "option('header','true').\\\n",
        "option('path','/content/operations_management.csv').\\\n",
        "load()"
      ],
      "metadata": {
        "id": "cDDV6YDVjllP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.printSchema()"
      ],
      "metadata": {
        "id": "nVllKFQgm2N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2 = data_frame.select('industry','value').\\\n",
        "where(data_frame.value > 10000).\\\n",
        "orderBy(desc('value'))"
      ],
      "metadata": {
        "id": "lRO05ziFn20V"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2.printSchema()"
      ],
      "metadata": {
        "id": "VCea1fIOpnKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_2.show(5)"
      ],
      "metadata": {
        "id": "v4Vq2npyqg4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or we can use filter instead of where clause to filter using value columns\n",
        "data_frame_3 = data_frame.select('industry','value').\\\n",
        "filter((col('value') > 200) & (col('industry') != 'total')).\\\n",
        "orderBy(desc('value'))"
      ],
      "metadata": {
        "id": "2mQT1ox6pvp5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_3.printSchema()"
      ],
      "metadata": {
        "id": "p1sSSqL6qb59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_3.show(5)"
      ],
      "metadata": {
        "id": "nabI5mSLqnnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Temp View\n",
        "data_frame_3.createOrReplaceTempView('data') #Here data is any name given to view"
      ],
      "metadata": {
        "id": "kFfD3tuUwMa-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the temp view data\n",
        "spark_operations.sql('''select industry, value\n",
        "from data\n",
        "where value >200 and\n",
        "industry !=\"total\" order by value desc\n",
        "''').show(5)"
      ],
      "metadata": {
        "id": "vJu31L62xUB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}